{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDG-43VWezbI",
        "outputId": "79f8e6c8-a526-440e-dd64-24e6973d262a"
      },
      "outputs": [],
      "source": [
        "# !pip install nltk\n",
        "# !pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# nltk.download('punkt')\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XNBJUxSqAZ42"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tag import pos_tag\n",
        "import string\n",
        "import re\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    pdf_text = \"\"\n",
        "    with open(pdf_path, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        for page in pdf_reader.pages:\n",
        "            pdf_text += page.extract_text()\n",
        "    return pdf_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xuEwoCHBLWJc"
      },
      "outputs": [],
      "source": [
        "def data_cleaning(text):\n",
        "    cleaned_text = text.replace('\\n', ' ').replace('\\t', ' ').strip()\n",
        "    return cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9VyHm_iodCAn"
      },
      "outputs": [],
      "source": [
        "def text_normalization(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    contractions = {\n",
        "        \"n't\": \" not\",\n",
        "        \"'s\": \" is\",\n",
        "        \"'re\": \" are\",\n",
        "        \"'ll\": \" will\",\n",
        "        \"'d\": \" would\",\n",
        "        \"'ve\": \" have\",\n",
        "        \"i.e\": \" that is\",\n",
        "    }\n",
        "    words = text.split()\n",
        "    expanded_words = [contractions[word] if word in contractions else word for word in words]\n",
        "    text = \" \".join(expanded_words)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PFrmRYvydEwW"
      },
      "outputs": [],
      "source": [
        "def tokenization(text):\n",
        "    words = word_tokenize(text)\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ccg9dC16dHyW"
      },
      "outputs": [],
      "source": [
        "def stop_words_removal(words):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return filtered_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "krRVUgcKdJ7m"
      },
      "outputs": [],
      "source": [
        "def lemmatization(words):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in words]\n",
        "    return lemmatized_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YT-mTJPkdMSG"
      },
      "outputs": [],
      "source": [
        "def part_of_speech_tagging(words):\n",
        "    pos_tags = pos_tag(words)\n",
        "    return pos_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "n0bF9bLkdPjG"
      },
      "outputs": [],
      "source": [
        "def save_to_text_file(processed_text, output_path):\n",
        "    with open(output_path, 'w', encoding='utf-8') as output_file:\n",
        "        output_file.write(processed_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iBeGP5rEdQ93"
      },
      "outputs": [],
      "source": [
        "def preprocess_and_save_to_txt(input_pdf_path, output_txt_path):\n",
        "    pdf_text = extract_text_from_pdf(input_pdf_path)\n",
        "    cleaned_text = data_cleaning(pdf_text)\n",
        "    normalized_text = text_normalization(cleaned_text)\n",
        "    tokenized_words = tokenization(normalized_text)\n",
        "    filtered_words = stop_words_removal(tokenized_words)\n",
        "    lemmatized_words = lemmatization(filtered_words)\n",
        "    pos_tags = part_of_speech_tagging(lemmatized_words)\n",
        "\n",
        "    processed_text = f\"Cleaned Text: {cleaned_text}\\n\\n\" \\\n",
        "                     f\"Normalized Text: {normalized_text}\\n\\n\" \\\n",
        "                     f\"Tokenized Words: {' '.join(tokenized_words)}\\n\\n\" \\\n",
        "                     f\"Filtered Words: {' '.join(filtered_words)}\\n\\n\" \\\n",
        "                     f\"Lemmatized Words: {' '.join(lemmatized_words)}\\n\\n\" \\\n",
        "                     f\"Part-of-Speech Tags: {str(pos_tags)}\"\n",
        "\n",
        "    save_to_text_file(processed_text, output_txt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bXTWWxJSdTAn"
      },
      "outputs": [],
      "source": [
        "preprocess_and_save_to_txt('input pdf path', 'input for processed file path')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1p6TEe-KdVWn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
